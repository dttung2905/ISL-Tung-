{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview\n",
    "\n",
    "- Resampling can be computationally expensive \n",
    "- we will discuss two of the most commonly used resampling methods, cross-validation and bootstrap \n",
    "- The process of evaluating a model's performance is known as model assessment , whereas the process of selecting the proper level of flexibility for a model is known as model selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross validation\n",
    "- Test error can be easily calculated if a designated test set is available. Unfortunately, this is usually not the case.\n",
    "- We consider a class of methods that estimate the test error rate by holding out a subset of the training observations from the fitting process and then applying the statistical learning method to those held out observations\n",
    "\n",
    "## 2.1 Drawbackks\n",
    "- Validation estimate of the test error rate ban be highly variable , depending on precisely which observations are included in the training and valid set\n",
    "- Validation set error rate may tend to overestimate the test error rate for the model fit on the entire data set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Leave-One-Out Cross validation\n",
    "- A single observation is used for the validation set, and the remaining observations will make up the training set\n",
    "- THe statistical method is fit on the n-1 training observation, and a prediction $\\hat{y_1}$ is made for the excluded observation\n",
    "- LOOCV estimate for the test MSE is the average of these n test error estimates \n",
    "\\begin{equation*} \n",
    "CV_(n) = \\frac{1}{n} \\sum_{i=1}^{n}(MSE)_i \n",
    "\\end{equation*}\n",
    "\n",
    "- Advantages: \n",
    "    - It has far less bias. because we perform n-1 time\n",
    "    - It thends not to overestimate the test error rate as much as the validation set approach does \n",
    "    \n",
    "- Disadvantages:\n",
    "    - Expensive to implement \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 k-fold CV\n",
    "- k-fold CV estimate is compuate by averaging these value \n",
    "\\begin{equation*} \n",
    "CV_(k) = \\frac{1}{k} \\sum_{i=1}^{k}(MSE)_i \n",
    "\\end{equation*}\n",
    "- advantages:\n",
    "    - Less computationally expensive \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Bias Variance Trade-off\n",
    "- LOOCV has low bias but high variance. WHen we perform LOOCV, we are in effect averaging the output of n fitted models each of which is trained on an almost identical set of observations , therefore, these outputs are highly positively correlated with eachother \n",
    "- Kfold has moderrate bias and variance \n",
    "- Often we choose k-fold with k = 5 or 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
